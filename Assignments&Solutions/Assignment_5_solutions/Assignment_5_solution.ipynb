{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Association mining\n",
    "\n",
    "## Objective of this assignment\n",
    "The overall objective is to understand how frequent itemsets can be extracted by\n",
    "the Apriori algorithm and be able to calculate and interpret association rules in terms of support and confidence.\n",
    "\n",
    "## ** Important: ** When handing in your homework:\n",
    "+ Hand in the notebook (and nothing else) named as follows: StudentName1_snumber_StudentName2_snumber.ipynb\n",
    "+ Provide clear and complete answers to the questions below under a separate header (not hidden somewhere in your source code), and make sure to explain your answers / motivate your choices. Add Markdown cells where necessary.\n",
    "+ Source code, output graphs, derivations, etc., should be included in the notebook.\n",
    "+ Hand-in: upload to Blackboard.\n",
    "+ Include name, student number, assignment (especially in filenames)!\n",
    "+ When working in pairs only one of you should upload the assignment, and report the name of your partner in your filename.\n",
    "+ For problems or questions: use the BB discussion board or email the student assistants.\n",
    "\n",
    "\n",
    "## Advised Reading and Exercise Material\n",
    "**The following reading material is recommended:**\n",
    "\n",
    "- Pang-Ning Tan, Michael Steinbach, and Vipin Kumar, *Introduction to Data Mining*, section 6.\n",
    "\n",
    "\n",
    "## Additional Tools\n",
    "For this exercise you will need to load the provided *apriorimining.py* script. \n",
    "\n",
    "\n",
    "##  5.1 Association mining for course data \n",
    "We will use the Apriori algorithm to automatically mine for associations. The Apriori algorithm is an adapted version of the script found here: https://github.com/nalinaksh/Association-Rule-Mining-Python\n",
    "\n",
    "Check out the script and doc and check if you understand how the association rules are computed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Toolbox.apriorimining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5.1.1\n",
    "\n",
    "(0 points) Look at the data file `Data/courses.txt` into Python. The data is represented in Table 1. Inspect the file Data/courses.txt and make sure you understand how the data in Table 1 is stored in the text file.\n",
    "\n",
    "##### Table 1\n",
    "|#  |   History |Math| Biology| Spanish | Economics| Physics | Chemistry | English  |  \n",
    "| :-------------: |:-------------:| :-----------:| :----------:| :------------:|:-------------:| :------------:|  :-------------: | :-------------: |\n",
    "|student 1 | 0| 1 | 0 | 0 | 1| 1 |1 |1   \n",
    "|student 2 | 1| 1 | 1 | 0 | 0| 1 |1 |1   \n",
    "|student 3 | 0| 1 | 0 | 1 | 0| 1 |0 |1   \n",
    "|student 4 | 0| 0 | 1 | 0 | 0| 1 |1 |0   \n",
    "|student 5 | 0| 1 | 0 | 0 | 0| 1 |1 |0        \n",
    "|student 6 | 0| 1 | 1 | 0 | 0| 1 |1 |1   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2\n",
    "(1 point) We will analyze the data in Table 1 automatically using the function `associationmining.generate_association_rules()` from the script. Analyze the data with $ minsupport  \\geq 80 \\% $ and $ minconfidence \\geq 100 \\%$.What\n",
    "are the generated association rules? What kind of conclusions can you make based on these association rules about the subjects that students took?  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Toolbox.apriorimining.generate_association_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click to type your answer for 5.1.2 here:*\n",
    "\n",
    "Answer:The inferred association rules show that all students took Physics course\n",
    "(Conf=100). Those who took Chemistry or Math course also took Physics.\n",
    "These results are quite logical, since Math, Physics, and Chemistry belong to\n",
    "technical disciplines and quite often occur together in the roster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##  5.2 Association mining for MovieLens data \n",
    "  \n",
    "  \n",
    "  In this part of the exercise we consider a Market Basket data set containing 943 users purchases of 1682 movies. A total of 100,000 movies\n",
    "have been purchased.The data set is called MovieLens100K and is provided by http://www.grouplens.org/node/73, see also the readme `MovieLensData.txt` in the data folder. The data currently considered is not the original data but modified for the apriori algorithm.\n",
    "\n",
    "#### 5.2.1\n",
    "  (0 points) The MovieLens data is stored in the file MovieLensData.txt. Inspect the file to see how the data is stored.\n",
    "\n",
    "\n",
    "#### 5.2.2 \n",
    "  (1 point) Find association rules using the function below with $ minsupport  \\geq 30 \\% $ and $ minconfidence \\geq 80 \\%$. What are the associations with strongest confidence? Do these associations make sense? You can use file Data/u.item to print the movie titles in stead of numbers. If you enter filename `MovieLensData.txt`, the script will provide an additional option for this. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Toolbox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d66336456d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mToolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapriorimining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_association_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Toolbox' is not defined"
     ]
    }
   ],
   "source": [
    "Toolbox.apriorimining.generate_association_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click to type your answer for 5.2.2 here:*\n",
    "\n",
    "Answer: The associations with the strongest confidence are:\n",
    "\n",
    "`Rule #73: { Empire Strikes Back, The (1980), Raiders of the Lost Ark (1981), Return of the Jedi (1983) } ==> { Star Wars (1977) }, sup= 31.18, conf= 99.66\n",
    "Rule #34: { Empire Strikes Back, The (1980), Return of the Jedi (1983) } ==> { Star Wars (1977) }, sup= 33.40, conf= 99.37\n",
    "Rule #54: { Pulp Fiction (1994), Return of the Jedi (1983) } ==> { Star Wars (1977) }, sup= 30.22, conf= 98.62\n",
    "Rule #63: { Raiders of the Lost Ark (1981), Return of the Jedi (1983) } ==> { Star Wars (1977) }, sup= 35.74, conf= 98.54\n",
    "Rule #48: { Return of the Jedi (1983), Toy Story (1995) } ==> { Star Wars (1977) }, sup= 35.31, conf= 97.94\n",
    "Rule #44: { Return of the Jedi (1983), Silence of the Lambs, The (1991) } ==> { Star Wars (1977) }, sup= 30.65, conf= 97.64\n",
    "Rule #45: { Return of the Jedi (1983), Twelve Monkeys (1995) } ==> { Star Wars (1977) }, sup= 30.54, conf= 97.63\n",
    "Rule #58: { Godfather, The (1972), Return of the Jedi (1983) } ==> { Star Wars (1977) }, sup= 31.92, conf= 97.10`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Answer: If we take a look at the names of the movies that are suggested, we\n",
    "can conclude that the association rules are reasonable.\n",
    "\n",
    "All the movies belong to the same genres (Adventure or Science Fiction), which\n",
    "is logical, since many people prefer to watch movies of particular genre. Pro-\n",
    "posed combinations also look reasonable. `Rule #34: { Empire Strikes Back, The (1980), Return of the Jedi (1983) } ==> { Star Wars (1977) }` implies that people who watch star wars movies, like to watch more star wars movies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 \n",
    "(1 point) Which movies have been watched by the most users? There are only few rules with more than three items. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click to type your answer for 5.2.3 here:*\n",
    "\n",
    "Answer:\n",
    "\n",
    "`set= { Star Wars (1977) },  sup= 61.82\n",
    "set= { Contact (1997) },  sup= 53.98\n",
    "set= { Fargo (1996) },  sup= 53.87\n",
    "set= { Return of the Jedi (1983) },  sup= 53.76\n",
    "set= { Liar Liar (1997) },  sup= 51.43` \n",
    "\n",
    "There are only a few rules with more than three items, because\n",
    "number of movies is large, while each user have watched only a few of them.\n",
    "That makes the matrix of User vs. Movies very sparse, and as a result there\n",
    "are only few movies that occurred in a combination very often to produce an\n",
    "assoociation rule with $ minsupport  \\geq 30 \\% $ and $ minconfidence \\geq 80 \\%$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4\n",
    "(0.5 points) Often we are interested in rules with high confidence. Is it possible for\n",
    "itemsets to have very low support but still have a very high confidence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Yes, it is possible. When the rule `{a} ==> {b}` occurs rarely, the support will be low. But if item `{a}`  almost never occurs without item `{b}`, the confidence of the rule `{a} ==> {b}` will be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Calculating support, confidence and interest\n",
    "\n",
    "Calculate these measures and write down how you computed things, not just the answers. \n",
    "\n",
    "\n",
    "#### 5.3.1\n",
    " Suppose we have market basket data consisting of 100 transactions and 20 items. The support for item $ \\text{a} = 45 \\%$, the support for item $ \\text{b} = 80 \\%$ and the support for itemset $ \\text{ {a,b }} = 30 \\%$. Let the support and confidence thresholds be 20$ \\%$ and 60$ \\%$, respectively.\n",
    "  \n",
    "1. (0.5 points) Compute the confidence of the association rule $ \\text{ {a } } \\rightarrow   \\text{{b }} $. Is the rule interesting according to the confidence measure?\n",
    "\n",
    "2. (0.5 points) Compute the interest measure (or lift, see slide 44 of chapter 6) for the association pattern $ \\text{ {a,b}}$. Describe the nature of the relationship between item $ \\text{a}$ and item $ \\text{b}$  in terms of the itemset measure.\n",
    "3. (1 points) What conclusion can you draw from the results of parts (1) and (2)?\n",
    "\n",
    "4. (1.5 points) Prove that if the confidence of the rule $ \\text{ {a } } \\rightarrow   \\text{{b }} $ is less than the support of $ \\text{ {b }}$  then\n",
    "$$\n",
    "c(  \\text{ {~a } } \\rightarrow   \\text{{b }})> c(  \\text{ {a } } \\rightarrow   \\text{{b }})\n",
    "$$\n",
    "and\n",
    "$$\n",
    "c(  \\text{ {~a } } \\rightarrow   \\text{{b }})> s( {b })\n",
    "$$\n",
    "\n",
    "where $ \\text{c(.)}$  denotes the rule confidence and  $ \\text{s(.)}$ denote the support of an itemset. \n",
    "\n",
    "Hint: To prove the statement rewrite the confidence and the support of the rule in terms of probabilities: \n",
    "$$\n",
    "c(  \\text{ {a } } \\rightarrow   \\text{{b }})=  \\frac{P( {a,b })}{P( {a })}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "s( {b })=P( {b })\n",
    "$$\n",
    "\n",
    "Further more, make use of probability rules such as $p(b) = p(\\text{~}a,b) + p(a,b)$ and $p(\\text{~}a) = 1 - p(a)$ and algebraic rules such as $$ \\frac{p(a,b)}{p(b)} < p(a) \\rightarrow 1 - \\frac{p(a,b)}{p(b)} > 1 - p(a) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click to type your answer for 5.3.1 here:*\n",
    "\n",
    "\n",
    "##### 1\n",
    "  $ c(\\text{ {a } } \\rightarrow   \\text{{b }}) = \\frac{ s(\\text{ {a } } ,  \\text{{b }})}{s(\\text{ {a } })} = \\frac{0.3}{0.45} = 0.66$ \n",
    "\n",
    "The confidence is higher than the threshold, so the rule is considered interesting. \n",
    "\n",
    "\n",
    "##### 2\n",
    " $I(\\text{{a,b}}) = \\frac{N * f_{11}}{f_{1+} * f_{+1}} = \\frac{100*30}{45*80} = 0.83 $\n",
    "\n",
    "The items are negatively correlated according to interest measure.\n",
    "\n",
    "##### 3\n",
    "High confidence rules may not be interesting. This conclusion is more important than the precise calculations!\n",
    "\n",
    "\n",
    "##### 4\n",
    "If $c(a \\rightarrow b) < s(b)$ then $c(\\text{~}a \\rightarrow b) > c(a \\rightarrow b)$:\n",
    "\n",
    "> Proof:\n",
    "$$ c(a \\rightarrow b) < s(b) $$ can be rewritten as \n",
    "$$ \\frac{p(a,b)}{p(a)} < p(b) $$ which implies that\n",
    "$$ \\frac{p(a,b)}{p(b)} < p(a) $$ and by the given algebraic rule\n",
    "$$ 1 - \\frac{p(a,b)}{p(b)} > 1 - p(a) $$ \n",
    "and by the given probability rules and basic algebra:\n",
    "$$ \\frac{p(b)}{p(b)} - \\frac{p(a,b)}{p(b)} > p(\\text{~}a) $$ which means\n",
    "$$ \\frac{p(b) - p(a,b)}{p(b)} > p(\\text{~}a) $$ and by the rule $p(b) = p(\\text{~}a,b) + p(a,b)$ we get\n",
    "$$ \\frac{p(\\text{~}a,b)}{p(b)} > p(\\text{~}a) $$ which implies that\n",
    "$$ \\frac{p(\\text{~}a,b)}{p(\\text{~}a)} > p(b) $$ and this can be rewritten in terms of support and confidence to \n",
    "$$ c(\\text{~}a \\rightarrow b) > s(b) $$\n",
    "\n",
    "And since $ c(\\text{~}a \\rightarrow b) > s(b) $ and $c(a \\rightarrow b) < s(b)$ we can conclude that $c(\\text{~}a \\rightarrow b) > c(a \\rightarrow b)$. \n",
    "This proof is worth 1.5 points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5.3.2\n",
    "\n",
    "(3 points) Consider the relationships between customers who buy high-definition televisions and exercise machines as shown in Table 2 and 3.\n",
    "\n",
    "1. Compute the odd ratios for both tables.\n",
    "2. Compute the $\\phi$-coefficient for both tables.\n",
    "3. Compute the interest factor for both tables.\n",
    "\n",
    "For Table 3 you should compute measures given above separately for College\n",
    "Students and for Adults. For each of the measures, describe how the direction\n",
    "of association changes when data is pooled together (Table 2) instead of being\n",
    "separated into two groups (Table 3)\n",
    "\n",
    "##### Table 2: Two way contingency table between the sale of high-definition television and exercise machine\n",
    "| |   Buy Exercise machine |     |     |\n",
    "| :------------- | -------------:| :-----------:| :----------:| \n",
    "| **Buy HDTV     ** | yes | no | total |\n",
    "| yes  | 105| 87 | 192 | \n",
    "| no | 40| 62 | 102 |   \n",
    "| total | 145 | 149 | 294 | \n",
    " \n",
    "\n",
    "##### Table 3: Example of three-way contingency table\n",
    "| | |   Buy Exercise machine |     |     |\n",
    "|--- | :------------- | -------------:| :-----------:| :----------:| \n",
    "|**Customer group** | **Buy HDTV     ** | yes | no | total |\n",
    "|College students | yes  | 2| 9 | 11 | \n",
    "| | no | 5| 20 | 25 |\n",
    "| Working adults | yes  | 103| 78 | 181 | \n",
    "| | no | 35| 42 | 77 |  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click to type your answer for 5.3.2 here:*\n",
    "\n",
    "##### 1\n",
    "For Table 2, odds ratio $\\frac{f_{11}f_{00}}{f_{10}f_{01}} =1.87 $. For Table 3, the odds ratios are 0.88 and 1.58.\n",
    "\n",
    "##### 2\n",
    "For Table 2, $\\phi = \\frac{Nf_{11} - f_{1+}f_{+1}}{\\sqrt{f_{1+}f_{+1}f_{0+}f_{+0}}} = 0.147$. For Table 3, the $\\phi$-coefficients are -0.02 and 0.104.\n",
    "\n",
    "##### 3\n",
    "For Table 2, $I = \\frac{Nf_{11}}{f_{1+}f_{+1}} = 1.108$. For Table 3, the interest factors are 0.935 and 1.06.\n",
    "\n",
    "There is a difference in the direction of association between groups. For college students the association is negative, while for working adults, it is positive. When you pool the data together the association becomes positive. \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
